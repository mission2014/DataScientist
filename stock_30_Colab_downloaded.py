# -*- coding: utf-8 -*-
"""Stock_30.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1W6rO-L9ZgTQA7nwg95ohPAuGAziSodxt
"""

#import the library and important packages for building the model
import pandas as pd   # perform data manipulation in Python
import numpy as np    #scientific computing, contains a powerful n-dimensional array object

from sklearn.linear_model import LinearRegression
from sklearn.svm import SVR
from sklearn.model_selection import train_test_split

import matplotlib.pyplot as plt
import seaborn as sns

# Code to read csv file into Colaboratory:
!pip install -U -q PyDrive
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials
# Authenticate and create the PyDrive client.
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

link = 'https://drive.google.com/open?id=1Gj1QpuzyrBxL0G33vvwmGdLFj3UkfmDw'

fluff, id = link.split('=')
print (id) # Verify that you have everything after '='

#sklearn classification, regression and clustering algorithms including support vector machines
#import the stock_30 .csv 
downloaded = drive.CreateFile({'id':id}) 
downloaded.GetContentFile('stock_30.csv')
df = pd.read_csv('stock_30.csv')

df.head()

z = df.iloc[1:,[1,2,3,4,5]]
z

z.hist()

df = df[['Stock\n Price','Variable1','Variable2']]
df

predict_stock = int(30) #'n=30' days
#Create another column (the target or dependent variable) shifted 'n' units up
df['Prediction'] = df[['Stock\n Price']].shift(-predict_stock)
print(df.head(10))

df.columns

df.Prediction.isna()

df.isna()

df.replace([np.inf, -np.inf], np.nan, inplace=True)
df.fillna(999, inplace=True)
print(df.head(10))

df.plot()

df.head(10)

df.dropna(axis = 0)
df.head(20)

df.replace([np.inf, -np.inf], np.nan, inplace=False)
print(df.head(10))

X = np.array(df.drop(['Prediction'],1))
#Remove the last 'n' rows
X = X[:-predict_stock]
print(X)

y = np.array(df['Prediction'])
y

# Get all of the y values except the last 'n' rows
y = y[:-predict_stock]
print(y)

# Split the data into 80% training and 20% testing
x_train, x_test, y_train, y_test = train_test_split(X, y, test_size= 0.2)

# Create and train the Support Vector Machine (Regressor)
svmr_rbf= SVR(kernel='rbf', C=1000, gamma=0.1)

#svr_rbf.fit(x_train, y_train)
x_train[np.isnan(x_train)] = np.median(x_train[~np.isnan(x_train)])
y_train[np.isnan(y_train)] = np.median(y_train[~np.isnan(y_train)])

svmr_rbf.fit(x_train,y_train)

#svm_confidence = svr_rbf.score(x_test, y_test)
svm_confidence = svmr_rbf.score(x_test,y_test)

print("svm confidence: ", svm_confidence)

# Create and train the Linear Regression  Model
LinearReg = LinearRegression()
# Train the model
LinearReg.fit(x_train, y_train)

# Testing Model: Score returns the coefficient of determination R^2 of the prediction. 
# The best possible score is 1.0
LinearReg_confidence = LinearReg.score(x_test, y_test)
print("LinearReg Confidence Level : ", LinearReg_confidence)

# Set x_forecast equal to the last 30 rows of the original data set from Adj. Close column
Predict_forecast = np.array(df.drop(['Prediction'],1))[-predict_stock:]
print(Predict_forecast)

# Print linear regression model predictions for the next 'n' days
LinearReg_prediction = LinearReg.predict(Predict_forecast)
print(LinearReg_prediction)

# Print support vector regressor model predictions for the next 'n' days
svm_prediction = svmr_rbf.predict(Predict_forecast)
print(svm_prediction)

import seaborn as sns
sns.boxplot(svm_prediction)

sns.heatmap(z)

sns.heatmap(X)

sns.heatmap(df)

